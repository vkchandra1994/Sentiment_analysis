{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Introduction\n",
    "\n",
    "Build models using Catboost, Lightgbm and NaiveBayes algorithm in Python. Given the text classification problem, we will clean data, create bag of words matrix, tf-idf matrix. \n",
    "\n",
    "Next we will create a simple voting ensemble from the predictions generated from these models here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "train_feats1 = pickle.load(open('./proxy/train_feats1.bin','rb'))\n",
    "train_feats2 = pickle.load(open('./proxy/train_feats2.bin','rb'))\n",
    "test_feats1 = pickle.load(open('./proxy/test_feats1.bin','rb'))\n",
    "test_feats2 = pickle.load(open('./proxy/test_feats2.bin','rb'))\n",
    "target = pickle.load(open('./proxy/labels.bin','rb'))\n",
    "User_ID = pickle.load(open('./proxy/userid.bin','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.681213\n",
       "0    0.318787\n",
       "Name: Is_Response, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Description</th>\n",
       "      <th>Browser_Used</th>\n",
       "      <th>Device_Used</th>\n",
       "      <th>Is_Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10326</td>\n",
       "      <td>The room was kind of clean but had a VERY stro...</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id10327</td>\n",
       "      <td>I stayed at the Crown Plaza April -- - April -...</td>\n",
       "      <td>Internet Explorer</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id10328</td>\n",
       "      <td>I booked this hotel through Hotwire at the low...</td>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id10329</td>\n",
       "      <td>Stayed here with husband and sons on the way t...</td>\n",
       "      <td>InternetExplorer</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id10330</td>\n",
       "      <td>My girlfriends and I stayed here to celebrate ...</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID                                        Description  \\\n",
       "0  id10326  The room was kind of clean but had a VERY stro...   \n",
       "1  id10327  I stayed at the Crown Plaza April -- - April -...   \n",
       "2  id10328  I booked this hotel through Hotwire at the low...   \n",
       "3  id10329  Stayed here with husband and sons on the way t...   \n",
       "4  id10330  My girlfriends and I stayed here to celebrate ...   \n",
       "\n",
       "        Browser_Used Device_Used Is_Response  \n",
       "0               Edge      Mobile   not happy  \n",
       "1  Internet Explorer      Mobile   not happy  \n",
       "2            Mozilla      Tablet   not happy  \n",
       "3   InternetExplorer     Desktop       happy  \n",
       "4               Edge      Tablet   not happy  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "happy        26521\n",
       "not happy    12411\n",
       "Name: Is_Response, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Is_Response.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# function to clean data\n",
    "\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "def cleanData(text, lowercase = False, remove_stops = False, stemming = False):\n",
    "    txt = str(text)\n",
    "    txt = re.sub(r'[^A-Za-z0-9\\s]',r'',txt)\n",
    "    txt = re.sub(r'\\n',r' ',txt)\n",
    "    \n",
    "    if lowercase:\n",
    "        txt = \" \".join([w.lower() for w in txt.split()])\n",
    "        \n",
    "    if remove_stops:\n",
    "        txt = \" \".join([w for w in txt.split() if w not in stops])\n",
    "    \n",
    "    if stemming:\n",
    "        st = PorterStemmer()\n",
    "        txt = \" \".join([st.stem(w) for w in txt.split()])\n",
    "\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## join data\n",
    "test['Is_Response'] = np.nan\n",
    "alldata = pd.concat([train, test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# clean description\n",
    "alldata['Description'] = alldata['Description'].map(lambda x: cleanData(x, lowercase=True, remove_stops=True, stemming=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# initialise the functions - we'll create separate models for each type.\n",
    "countvec = CountVectorizer(analyzer='word', ngram_range = (1,2), min_df=150, max_features=500)\n",
    "tfidfvec = TfidfVectorizer(analyzer='word', ngram_range = (1,2), min_df =150, max_features=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create features\n",
    "bagofwords = countvec.fit_transform(alldata['Description'])\n",
    "tfidfdata = tfidfvec.fit_transform(alldata['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# label encode categorical features in data given\n",
    "cols = ['Browser_Used','Device_Used']\n",
    "\n",
    "for x in cols:\n",
    "    lbl = LabelEncoder()\n",
    "    alldata[x] = lbl.fit_transform(alldata[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create dataframe for features\n",
    "bow_df = pd.DataFrame(bagofwords.todense())\n",
    "tfidf_df = pd.DataFrame(tfidfdata.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# set column names\n",
    "bow_df.columns = ['col'+ str(x) for x in bow_df.columns]\n",
    "tfidf_df.columns = ['col' + str(x) for x in tfidf_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create separate data frame for bag of words and tf-idf\n",
    "\n",
    "bow_df_train = bow_df[:len(train)]\n",
    "bow_df_test = bow_df[len(train):]\n",
    "\n",
    "tfid_df_train = tfidf_df[:len(train)]\n",
    "tfid_df_test = tfidf_df[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# split the merged data file into train and test respectively\n",
    "train_feats = alldata[~pd.isnull(alldata.Is_Response)]\n",
    "test_feats = alldata[pd.isnull(alldata.Is_Response)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "### set target variable\n",
    "\n",
    "train_feats['Is_Response'] = [1 if x == 'happy' else 0 for x in train_feats['Is_Response']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# merge count (bag of word) features into train\n",
    "train_feats1 = pd.concat([train_feats[cols], bow_df_train], axis = 1)\n",
    "test_feats1 = pd.concat([test_feats[cols], bow_df_test], axis=1)\n",
    "\n",
    "test_feats1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# merge into a new data frame with tf-idf features\n",
    "train_feats2 = pd.concat([train_feats[cols], tfid_df_train], axis=1)\n",
    "test_feats2 = pd.concat([test_feats[cols], tfid_df_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# let's check cross validation score of the model\n",
    "# cv score acts a unbiased estimate of models accuracy on unseen data\n",
    "\n",
    "mod1 = GaussianNB()\n",
    "target = train_feats['Is_Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.78261428  0.77099923  0.7784485   0.77793475  0.78628307]\n"
     ]
    }
   ],
   "source": [
    "## Naive Bayes 1\n",
    "print(cross_val_score(mod1, train_feats1, target, cv=5, scoring=make_scorer(accuracy_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.80559836  0.81274082  0.80863088  0.81274082  0.80362189]\n"
     ]
    }
   ],
   "source": [
    "## Naive Bayes 2 - tfidf is giving higher CV score\n",
    "print(cross_val_score(mod1, train_feats2, target, cv=5, scoring=make_scorer(accuracy_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# make our first set of predictions\n",
    "\n",
    "clf1 = GaussianNB()\n",
    "clf1.fit(train_feats1, target)\n",
    "\n",
    "clf2 = GaussianNB()\n",
    "clf2.fit(train_feats2, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "preds1 = clf1.predict(test_feats1)\n",
    "preds2 = clf2.predict(test_feats2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def to_labels(x):\n",
    "    if x == 1:\n",
    "        return \"happy\"\n",
    "    return \"not_happy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sub1 = pd.DataFrame({'User_ID':test.User_ID, 'Is_Response':preds1})\n",
    "sub1['Is_Response'] = sub1['Is_Response'].map(lambda x: to_labels(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sub2 = pd.DataFrame({'User_ID':test.User_ID, 'Is_Response':preds2})\n",
    "sub2['Is_Response'] = sub2['Is_Response'].map(lambda x: to_labels(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sub1 = sub1[['User_ID', 'Is_Response']]\n",
    "sub2 = sub2[['User_ID', 'Is_Response']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## write submission files\n",
    "sub1.to_csv('submissions/sub1_cv.csv', index=False)\n",
    "sub2.to_csv('submissions/sub2_tf.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### LightGBM - 1\n",
    "\n",
    "We are prefering lightgbm over xgboost because of its speed. <br />\n",
    "In this model, we'll use count features for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# set the data in format lgb accepts\n",
    "d_train = lgb.Dataset(train_feats1, label = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## set parameters\n",
    "## you can tune the parameters can try to better score\n",
    "\n",
    "params = {'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'num_iterations': 200,\n",
    "    'metric': 'binary_error',\n",
    "    'learning_rate': 0.05, \n",
    "    'max_depth': 12, \n",
    "    'num_leaves': 21, \n",
    "    'feature_fraction': 0.5, \n",
    "    'bagging_fraction': 0.9, \n",
    "    'bagging_freq': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\tcv_agg's binary_error: 0.194596 + 0.00269656\n",
      "[40]\tcv_agg's binary_error: 0.17641 + 0.00295816\n",
      "[60]\tcv_agg's binary_error: 0.164338 + 0.00282463\n",
      "[80]\tcv_agg's binary_error: 0.15545 + 0.00203493\n",
      "[100]\tcv_agg's binary_error: 0.14944 + 0.00251394\n",
      "[120]\tcv_agg's binary_error: 0.144534 + 0.00221926\n",
      "[140]\tcv_agg's binary_error: 0.140476 + 0.00302015\n",
      "[160]\tcv_agg's binary_error: 0.137239 + 0.00288219\n",
      "[180]\tcv_agg's binary_error: 0.135184 + 0.00259829\n",
      "[200]\tcv_agg's binary_error: 0.13277 + 0.00313745\n",
      "[220]\tcv_agg's binary_error: 0.131126 + 0.00334159\n",
      "[240]\tcv_agg's binary_error: 0.129816 + 0.00411599\n",
      "[260]\tcv_agg's binary_error: 0.129148 + 0.0040012\n",
      "[280]\tcv_agg's binary_error: 0.128069 + 0.00373029\n",
      "[300]\tcv_agg's binary_error: 0.126991 + 0.00342644\n",
      "[320]\tcv_agg's binary_error: 0.126734 + 0.00341319\n",
      "[340]\tcv_agg's binary_error: 0.126066 + 0.00342685\n",
      "[360]\tcv_agg's binary_error: 0.125552 + 0.00321423\n",
      "[380]\tcv_agg's binary_error: 0.124756 + 0.00355743\n",
      "[400]\tcv_agg's binary_error: 0.124371 + 0.00324306\n",
      "[420]\tcv_agg's binary_error: 0.124268 + 0.00297878\n",
      "[440]\tcv_agg's binary_error: 0.124217 + 0.00263837\n"
     ]
    }
   ],
   "source": [
    "lgb_cv = lgb.cv(params, d_train, num_boost_round=600, nfold= 5, shuffle=True, stratified=True, verbose_eval=20, early_stopping_rounds=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## get nround value which hd lowest error\n",
    "nround = lgb_cv['binary_error-mean'].index(np.min(lgb_cv['binary_error-mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## train the model\n",
    "model = lgb.train(params, d_train, num_boost_round=nround)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## make predictions\n",
    "preds = model.predict(test_feats1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# make submission\n",
    "\n",
    "def to_labels(x):\n",
    "    if x > 0.:  # cutoff - you can change it and see if accuracy improves or plot AUC curve. \n",
    "        return \"happy\"\n",
    "    return \"not_happy\"\n",
    "sub3 = pd.DataFrame({'User_ID':test.User_ID, 'Is_Response':preds})\n",
    "sub3['Is_Response'] = sub3['Is_Response'].map(lambda x: to_labels(x))\n",
    "sub3 = sub3[['User_ID','Is_Response']]\n",
    "sub3.to_csv('submissions/sub3_lgb.csv', index=False) # 0.85518"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Is_Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id80132</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id80133</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id80134</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id80135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id80136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id80137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>id80138</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>id80139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>id80140</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>id80141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>id80142</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>id80143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>id80144</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>id80145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>id80146</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>id80147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>id80148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>id80149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>id80150</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>id80151</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>id80152</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>id80153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>id80154</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>id80155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>id80156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>id80157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>id80158</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>id80159</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>id80160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>id80161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29374</th>\n",
       "      <td>id109506</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29375</th>\n",
       "      <td>id109507</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29376</th>\n",
       "      <td>id109508</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29377</th>\n",
       "      <td>id109509</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29378</th>\n",
       "      <td>id109510</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29379</th>\n",
       "      <td>id109511</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29380</th>\n",
       "      <td>id109512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29381</th>\n",
       "      <td>id109513</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29382</th>\n",
       "      <td>id109514</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29383</th>\n",
       "      <td>id109515</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29384</th>\n",
       "      <td>id109516</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29385</th>\n",
       "      <td>id109517</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29386</th>\n",
       "      <td>id109518</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29387</th>\n",
       "      <td>id109519</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29388</th>\n",
       "      <td>id109520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29389</th>\n",
       "      <td>id109521</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29390</th>\n",
       "      <td>id109522</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29391</th>\n",
       "      <td>id109523</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29392</th>\n",
       "      <td>id109524</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29393</th>\n",
       "      <td>id109525</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29394</th>\n",
       "      <td>id109526</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29395</th>\n",
       "      <td>id109527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29396</th>\n",
       "      <td>id109528</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29397</th>\n",
       "      <td>id109529</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29398</th>\n",
       "      <td>id109530</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29399</th>\n",
       "      <td>id109531</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29400</th>\n",
       "      <td>id109532</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29401</th>\n",
       "      <td>id109533</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29402</th>\n",
       "      <td>id109534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29403</th>\n",
       "      <td>id109535</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29404 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        User_ID  Is_Response\n",
       "0       id80132            0\n",
       "1       id80133            1\n",
       "2       id80134            1\n",
       "3       id80135            0\n",
       "4       id80136            1\n",
       "5       id80137            1\n",
       "6       id80138            1\n",
       "7       id80139            0\n",
       "8       id80140            1\n",
       "9       id80141            1\n",
       "10      id80142            1\n",
       "11      id80143            1\n",
       "12      id80144            0\n",
       "13      id80145            0\n",
       "14      id80146            0\n",
       "15      id80147            0\n",
       "16      id80148            0\n",
       "17      id80149            1\n",
       "18      id80150            1\n",
       "19      id80151            1\n",
       "20      id80152            1\n",
       "21      id80153            1\n",
       "22      id80154            1\n",
       "23      id80155            0\n",
       "24      id80156            0\n",
       "25      id80157            0\n",
       "26      id80158            1\n",
       "27      id80159            0\n",
       "28      id80160            1\n",
       "29      id80161            0\n",
       "...         ...          ...\n",
       "29374  id109506            0\n",
       "29375  id109507            1\n",
       "29376  id109508            0\n",
       "29377  id109509            0\n",
       "29378  id109510            1\n",
       "29379  id109511            0\n",
       "29380  id109512            1\n",
       "29381  id109513            0\n",
       "29382  id109514            0\n",
       "29383  id109515            1\n",
       "29384  id109516            1\n",
       "29385  id109517            0\n",
       "29386  id109518            0\n",
       "29387  id109519            1\n",
       "29388  id109520            1\n",
       "29389  id109521            1\n",
       "29390  id109522            1\n",
       "29391  id109523            0\n",
       "29392  id109524            1\n",
       "29393  id109525            1\n",
       "29394  id109526            1\n",
       "29395  id109527            0\n",
       "29396  id109528            0\n",
       "29397  id109529            1\n",
       "29398  id109530            1\n",
       "29399  id109531            1\n",
       "29400  id109532            1\n",
       "29401  id109533            1\n",
       "29402  id109534            1\n",
       "29403  id109535            1\n",
       "\n",
       "[29404 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### LightGBM - 2\n",
    "\n",
    "In this model, we'll use tf-idf features for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# set data format\n",
    "d_train = lgb.Dataset(train_feats2, label = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## set parameters\n",
    "## you can tune the parameters can try to better score\n",
    "\n",
    "params = {'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'num_iterations': 200,\n",
    "    'metric': 'binary_error',\n",
    "    'learning_rate': 0.05, \n",
    "    'max_depth': 12, \n",
    "    'num_leaves': 21, \n",
    "    'feature_fraction': 0.5, \n",
    "    'bagging_fraction': 0.9, \n",
    "    'bagging_freq': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\tcv_agg's binary_error: 0.190358 + 0.00340262\n",
      "[40]\tcv_agg's binary_error: 0.173405 + 0.00222938\n",
      "[60]\tcv_agg's binary_error: 0.163465 + 0.00241333\n",
      "[80]\tcv_agg's binary_error: 0.154192 + 0.00280347\n",
      "[100]\tcv_agg's binary_error: 0.148156 + 0.00248319\n",
      "[120]\tcv_agg's binary_error: 0.144072 + 0.00268211\n",
      "[140]\tcv_agg's binary_error: 0.140476 + 0.00198786\n",
      "[160]\tcv_agg's binary_error: 0.13783 + 0.00243854\n",
      "[180]\tcv_agg's binary_error: 0.135441 + 0.00255368\n",
      "[200]\tcv_agg's binary_error: 0.133772 + 0.00208681\n",
      "[220]\tcv_agg's binary_error: 0.132308 + 0.00229294\n",
      "[240]\tcv_agg's binary_error: 0.130741 + 0.00207624\n",
      "[260]\tcv_agg's binary_error: 0.129662 + 0.00299886\n",
      "[280]\tcv_agg's binary_error: 0.129225 + 0.00256252\n",
      "[300]\tcv_agg's binary_error: 0.128891 + 0.00302137\n",
      "[320]\tcv_agg's binary_error: 0.128224 + 0.0030393\n",
      "[340]\tcv_agg's binary_error: 0.128198 + 0.00329641\n"
     ]
    }
   ],
   "source": [
    "## do cross validation to find nround i.e. at this round (iteration) we can expect lowest error\n",
    "lgb_cv = lgb.cv(params, d_train, num_boost_round=500, nfold= 5, shuffle=True, stratified=True, verbose_eval=20, early_stopping_rounds=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get nround value\n",
    "nround = lgb_cv['binary_error-mean'].index(np.min(lgb_cv['binary_error-mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "model = lgb.train(params, d_train, num_boost_round=nround)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# make prediction\n",
    "preds = model.predict(test_feats2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# make submission\n",
    "\n",
    "def to_labels(x):\n",
    "    if x > 0.73:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "sub4 = pd.DataFrame({'User_ID':User_ID, 'Is_Response':preds})\n",
    "sub4['Is_Response'] = sub4['Is_Response'].map(lambda x: to_labels(x))\n",
    "sub4 = sub4[['User_ID','Is_Response']]\n",
    "sub4.to_csv('./output/sub4.csv', index=False) # 0.84925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"./output/ensemble.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_labels(x):\n",
    "    if x > 0.73:\n",
    "        return \"happy\"\n",
    "    return \"not_happy\"\n",
    "\n",
    "submission['Is_Response'] = submission['Is_Response'].map(lambda x: to_labels(x))\n",
    "submission.to_csv('./output/final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Is_Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id100001</td>\n",
       "      <td>not_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id100002</td>\n",
       "      <td>not_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id100003</td>\n",
       "      <td>not_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id100004</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id100005</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id100006</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>id100007</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>id100008</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>id100009</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>id100010</td>\n",
       "      <td>not_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>id100011</td>\n",
       "      <td>not_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>id100012</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>id100013</td>\n",
       "      <td>not_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>id100014</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>id100015</td>\n",
       "      <td>not_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>id100016</td>\n",
       "      <td>not_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>id100017</td>\n",
       "      <td>not_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>id100018</td>\n",
       "      <td>not_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>id100019</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>id100020</td>\n",
       "      <td>not_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>id100021</td>\n",
       "      <td>not_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>id100022</td>\n",
       "      <td>not_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>id100023</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>id100024</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>id100025</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>id100026</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>id100027</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>id100028</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>id100029</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>id100030</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29374</th>\n",
       "      <td>id99970</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29375</th>\n",
       "      <td>id99971</td>\n",
       "      <td>not_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29376</th>\n",
       "      <td>id99972</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29377</th>\n",
       "      <td>id99973</td>\n",
       "      <td>not_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29378</th>\n",
       "      <td>id99974</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29379</th>\n",
       "      <td>id99975</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29380</th>\n",
       "      <td>id99976</td>\n",
       "      <td>not_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29381</th>\n",
       "      <td>id99977</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29382</th>\n",
       "      <td>id99978</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29383</th>\n",
       "      <td>id99979</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29384</th>\n",
       "      <td>id99980</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29385</th>\n",
       "      <td>id99981</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29386</th>\n",
       "      <td>id99982</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29387</th>\n",
       "      <td>id99983</td>\n",
       "      <td>not_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29388</th>\n",
       "      <td>id99984</td>\n",
       "      <td>not_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29389</th>\n",
       "      <td>id99985</td>\n",
       "      <td>not_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29390</th>\n",
       "      <td>id99986</td>\n",
       "      <td>not_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29391</th>\n",
       "      <td>id99987</td>\n",
       "      <td>not_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29392</th>\n",
       "      <td>id99988</td>\n",
       "      <td>not_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29393</th>\n",
       "      <td>id99989</td>\n",
       "      <td>not_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29394</th>\n",
       "      <td>id99990</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29395</th>\n",
       "      <td>id99991</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29396</th>\n",
       "      <td>id99992</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29397</th>\n",
       "      <td>id99993</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29398</th>\n",
       "      <td>id99994</td>\n",
       "      <td>not_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29399</th>\n",
       "      <td>id99995</td>\n",
       "      <td>not_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29400</th>\n",
       "      <td>id99996</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29401</th>\n",
       "      <td>id99997</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29402</th>\n",
       "      <td>id99998</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29403</th>\n",
       "      <td>id99999</td>\n",
       "      <td>not_happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29404 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        User_ID Is_Response\n",
       "0      id100001   not_happy\n",
       "1      id100002   not_happy\n",
       "2      id100003   not_happy\n",
       "3      id100004       happy\n",
       "4      id100005       happy\n",
       "5      id100006       happy\n",
       "6      id100007       happy\n",
       "7      id100008       happy\n",
       "8      id100009       happy\n",
       "9      id100010   not_happy\n",
       "10     id100011   not_happy\n",
       "11     id100012       happy\n",
       "12     id100013   not_happy\n",
       "13     id100014       happy\n",
       "14     id100015   not_happy\n",
       "15     id100016   not_happy\n",
       "16     id100017   not_happy\n",
       "17     id100018   not_happy\n",
       "18     id100019       happy\n",
       "19     id100020   not_happy\n",
       "20     id100021   not_happy\n",
       "21     id100022   not_happy\n",
       "22     id100023       happy\n",
       "23     id100024       happy\n",
       "24     id100025       happy\n",
       "25     id100026       happy\n",
       "26     id100027       happy\n",
       "27     id100028       happy\n",
       "28     id100029       happy\n",
       "29     id100030       happy\n",
       "...         ...         ...\n",
       "29374   id99970       happy\n",
       "29375   id99971   not_happy\n",
       "29376   id99972       happy\n",
       "29377   id99973   not_happy\n",
       "29378   id99974       happy\n",
       "29379   id99975       happy\n",
       "29380   id99976   not_happy\n",
       "29381   id99977       happy\n",
       "29382   id99978       happy\n",
       "29383   id99979       happy\n",
       "29384   id99980       happy\n",
       "29385   id99981       happy\n",
       "29386   id99982       happy\n",
       "29387   id99983   not_happy\n",
       "29388   id99984   not_happy\n",
       "29389   id99985   not_happy\n",
       "29390   id99986   not_happy\n",
       "29391   id99987   not_happy\n",
       "29392   id99988   not_happy\n",
       "29393   id99989   not_happy\n",
       "29394   id99990       happy\n",
       "29395   id99991       happy\n",
       "29396   id99992       happy\n",
       "29397   id99993       happy\n",
       "29398   id99994   not_happy\n",
       "29399   id99995   not_happy\n",
       "29400   id99996       happy\n",
       "29401   id99997       happy\n",
       "29402   id99998       happy\n",
       "29403   id99999   not_happy\n",
       "\n",
       "[29404 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### CatBoost\n",
    "\n",
    "Catboost is a new package recently launched by Yandex. It is said that it works well when the data has many categorical features. We'll use it on count data and see it our model improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## import library\n",
    "from catboost import CatBoostClassifier,cv, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## catboost accepts categorical columns as a list of column numbers. In this data, all columns are categorical\n",
    "cat_cols = [x for x in range(502)] ## 502 == train_feats1.shape[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## set parameters\n",
    "## you can refer the parameters here: https://tech.yandex.com/catboost/doc/dg/concepts/python-reference_parameters-list-docpage/#python-reference_parameters-list\n",
    "param = {\n",
    "    'use_best_model':True,\n",
    "    'loss_function':'CrossEntropy',\n",
    "    'eval_metric':'Accuracy',\n",
    "    'iterations':1000,\n",
    "    'depth':6,\n",
    "    'learning_rate':0.03,\n",
    "    'rsm':0.3,\n",
    "    'random_seed':2017,\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## for doing cross validation, set data in Pool format\n",
    "my_dt =  Pool(train_feats1, \n",
    "           label=target,\n",
    "           cat_features=cat_cols,\n",
    "           column_description=None,\n",
    "           delimiter='\\t',\n",
    "           has_header=None,\n",
    "           weight=None, \n",
    "           baseline=None,\n",
    "           feature_names=None,\n",
    "           thread_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## run cv to get best iteration\n",
    "ctb_cv = cv(param, my_dt, fold_count=5, random_seed=2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# fetch best round\n",
    "best_round = ctb_cv['b\\'Accuracy\\'_test_avg'].index(np.max(ctb_cv['b\\'Accuracy\\'_test_avg']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## define the classifer model\n",
    "model = CatBoostClassifier(iterations=best_round, learning_rate=0.03,rsm = 0.3 ,depth=6, eval_metric='Accuracy', random_seed=2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## train model\n",
    "model.fit(my_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## make predictions\n",
    "preds = model.predict(test_feats1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## make submission\n",
    "sub5 = pd.DataFrame({'User_ID':test.User_ID, 'Is_Response':preds})\n",
    "sub5['Is_Response'] = ['happy' if x == 1 else 'not_happy' for x in sub5['Is_Response']]\n",
    "sub5 = sub5[['User_ID','Is_Response']]\n",
    "sub5.to_csv('submissions/sub5_cb.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
